{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aef4721a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/rickiwasho/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.3\n"
     ]
    }
   ],
   "source": [
    "#import re\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# sklearn\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#nlp\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "#import pyLDAvis\n",
    "#import pyLDAvis.gensim_models  # don't skip this\n",
    "\n",
    "import nltk; nltk.download('stopwords')\n",
    "import spacy\n",
    "print(spacy.__version__)\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "786b14a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>country</th>\n",
       "      <th>media_outlet</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>id_journalist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49234</td>\n",
       "      <td>chile</td>\n",
       "      <td>horas24</td>\n",
       "      <td>https://www.24horas.cl/coronavirus/tia-pikachu...</td>\n",
       "      <td>\"Tía Pikachu\" por parte empadronado: \"Estoy co...</td>\n",
       "      <td>Ha sufrido los embates del carro lanza aguas,...</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49252</td>\n",
       "      <td>chile</td>\n",
       "      <td>horas24</td>\n",
       "      <td>https://www.24horas.cl/nacional/tia-pikachu-po...</td>\n",
       "      <td>\"Tía Pikachu\" por parte empadronado: \"Estoy co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49277</td>\n",
       "      <td>chile</td>\n",
       "      <td>horas24</td>\n",
       "      <td>https://www.24horas.cl/nacional/los-toscanini-...</td>\n",
       "      <td>Los Toscanini: Cae banda que abastecía a crimi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id country media_outlet  \\\n",
       "0  49234   chile      horas24   \n",
       "1  49252   chile      horas24   \n",
       "2  49277   chile      horas24   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.24horas.cl/coronavirus/tia-pikachu...   \n",
       "1  https://www.24horas.cl/nacional/tia-pikachu-po...   \n",
       "2  https://www.24horas.cl/nacional/los-toscanini-...   \n",
       "\n",
       "                                               title  \\\n",
       "0  \"Tía Pikachu\" por parte empadronado: \"Estoy co...   \n",
       "1  \"Tía Pikachu\" por parte empadronado: \"Estoy co...   \n",
       "2  Los Toscanini: Cae banda que abastecía a crimi...   \n",
       "\n",
       "                                                text        date    year  \\\n",
       "0   Ha sufrido los embates del carro lanza aguas,...  2020-09-01  2020.0   \n",
       "1                                                NaN  2020-09-01  2020.0   \n",
       "2                                                NaN  2020-09-01  2020.0   \n",
       "\n",
       "   id_journalist  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import dataset \n",
    "dataset = pd.read_csv(\"data/chile_2020-09.csv\")[:100]\n",
    "print(len(dataset))\n",
    "display(dataset.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1d7f4fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Tía Pikachu\" por parte empadronado: \"Estoy co...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RM alcanza sus mejores índices de calidad de a...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Paro de camioneros: Supermercados preocupados ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sernac recibió más de 400 reclamos durante la ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Denuncian desabastecimiento en el sur del país...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Rodolfo Carter: \"Ser comunista hoy es ser mili...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Municipio afirma que baja de ventas llevó a ce...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Corte declara admisible recurso de protección ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>\"Matamos a cuanto hueón pillamos\": audio inédi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Gobierno presentará querella por polémica \"fie...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content terms\n",
       "0   \"Tía Pikachu\" por parte empadronado: \"Estoy co...      \n",
       "3   RM alcanza sus mejores índices de calidad de a...      \n",
       "6   Paro de camioneros: Supermercados preocupados ...      \n",
       "7   Sernac recibió más de 400 reclamos durante la ...      \n",
       "8   Denuncian desabastecimiento en el sur del país...      \n",
       "..                                                ...   ...\n",
       "95  Rodolfo Carter: \"Ser comunista hoy es ser mili...      \n",
       "96  Municipio afirma que baja de ventas llevó a ce...      \n",
       "97  Corte declara admisible recurso de protección ...      \n",
       "98  \"Matamos a cuanto hueón pillamos\": audio inédi...      \n",
       "99  Gobierno presentará querella por polémica \"fie...      \n",
       "\n",
       "[90 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "content = dataset[\"title\"] + '. ' + dataset[\"text\"]\n",
    "content.replace(\"\",np.nan,inplace=True)\n",
    "content.dropna(inplace=True)\n",
    "#terms = content['terms']\n",
    "dataset = pd.DataFrame({'content':content, 'terms': \"\"})\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ab702c",
   "metadata": {},
   "source": [
    "Extraer contexto: conceptos claves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e6eb9634",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Pattern 1: NOUN de NOUN\n",
    "pattern_1 = [{\"POS\": \"NOUN\"},{\"LOWER\": \"de\"}, {\"POS\": \"NOUN\"}]\n",
    "matcher.add(\"NOUN-de-NOUN\", [pattern_1])\n",
    "\n",
    "# Pattern 2: NOUN ADJ\n",
    "pattern_2 = [{\"POS\": \"NOUN\"}, {\"POS\": \"ADJ\"}]\n",
    "matcher.add(\"NOUN-ADJ\", [pattern_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e3df06e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Tía Pikachu\" por parte empadronado: \"Estoy co...</td>\n",
       "      <td>parte empadronado; par de oportunidades; estal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RM alcanza sus mejores índices de calidad de a...</td>\n",
       "      <td>jornada de CyberDay; jornada de CyberDay; falt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Paro de camioneros: Supermercados preocupados ...</td>\n",
       "      <td>acusación constitucional; Paro de camiones; pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sernac recibió más de 400 reclamos durante la ...</td>\n",
       "      <td>ultimátum de acusación; acusación constitucion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Denuncian desabastecimiento en el sur del país...</td>\n",
       "      <td>serie de instancias; participación ciudadana; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Rodolfo Carter: \"Ser comunista hoy es ser mili...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Municipio afirma que baja de ventas llevó a ce...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Corte declara admisible recurso de protección ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>\"Matamos a cuanto hueón pillamos\": audio inédi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Gobierno presentará querella por polémica \"fie...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  \\\n",
       "0   \"Tía Pikachu\" por parte empadronado: \"Estoy co...   \n",
       "3   RM alcanza sus mejores índices de calidad de a...   \n",
       "6   Paro de camioneros: Supermercados preocupados ...   \n",
       "7   Sernac recibió más de 400 reclamos durante la ...   \n",
       "8   Denuncian desabastecimiento en el sur del país...   \n",
       "..                                                ...   \n",
       "95  Rodolfo Carter: \"Ser comunista hoy es ser mili...   \n",
       "96  Municipio afirma que baja de ventas llevó a ce...   \n",
       "97  Corte declara admisible recurso de protección ...   \n",
       "98  \"Matamos a cuanto hueón pillamos\": audio inédi...   \n",
       "99  Gobierno presentará querella por polémica \"fie...   \n",
       "\n",
       "                                                terms  \n",
       "0   parte empadronado; par de oportunidades; estal...  \n",
       "3   jornada de CyberDay; jornada de CyberDay; falt...  \n",
       "6   acusación constitucional; Paro de camiones; pr...  \n",
       "7   ultimátum de acusación; acusación constitucion...  \n",
       "8   serie de instancias; participación ciudadana; ...  \n",
       "..                                                ...  \n",
       "95                                                     \n",
       "96                                                     \n",
       "97                                                     \n",
       "98                                                     \n",
       "99                                                     \n",
       "\n",
       "[90 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(dataset)):\n",
    "    doc = nlp(dataset.iloc[i]['content'])\n",
    "    matches = matcher(doc)\n",
    "    categories = \"\"\n",
    "    for match_id, start, end in matches:\n",
    "        string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "        span = doc[start:end]  # The matched span\n",
    "        categories = categories + span.text + \"; \"\n",
    "    \n",
    "    dataset['terms'][i] = categories\n",
    "    \n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "13c423a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>terms</th>\n",
       "      <th>most_common</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Tía Pikachu\" por parte empadronado: \"Estoy co...</td>\n",
       "      <td>parte empadronado; par de oportunidades; estal...</td>\n",
       "      <td>parte empadronado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RM alcanza sus mejores índices de calidad de a...</td>\n",
       "      <td>jornada de CyberDay; jornada de CyberDay; falt...</td>\n",
       "      <td>ultimátum de acusación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Paro de camioneros: Supermercados preocupados ...</td>\n",
       "      <td>acusación constitucional; Paro de camiones; pr...</td>\n",
       "      <td>mujeres semidesnudas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sernac recibió más de 400 reclamos durante la ...</td>\n",
       "      <td>ultimátum de acusación; acusación constitucion...</td>\n",
       "      <td>mujeres semidesnudas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Denuncian desabastecimiento en el sur del país...</td>\n",
       "      <td>serie de instancias; participación ciudadana; ...</td>\n",
       "      <td>venta de licencias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Rodolfo Carter: \"Ser comunista hoy es ser mili...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Municipio afirma que baja de ventas llevó a ce...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Corte declara admisible recurso de protección ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>\"Matamos a cuanto hueón pillamos\": audio inédi...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Gobierno presentará querella por polémica \"fie...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  \\\n",
       "0   \"Tía Pikachu\" por parte empadronado: \"Estoy co...   \n",
       "3   RM alcanza sus mejores índices de calidad de a...   \n",
       "6   Paro de camioneros: Supermercados preocupados ...   \n",
       "7   Sernac recibió más de 400 reclamos durante la ...   \n",
       "8   Denuncian desabastecimiento en el sur del país...   \n",
       "..                                                ...   \n",
       "95  Rodolfo Carter: \"Ser comunista hoy es ser mili...   \n",
       "96  Municipio afirma que baja de ventas llevó a ce...   \n",
       "97  Corte declara admisible recurso de protección ...   \n",
       "98  \"Matamos a cuanto hueón pillamos\": audio inédi...   \n",
       "99  Gobierno presentará querella por polémica \"fie...   \n",
       "\n",
       "                                                terms             most_common  \n",
       "0   parte empadronado; par de oportunidades; estal...       parte empadronado  \n",
       "3   jornada de CyberDay; jornada de CyberDay; falt...  ultimátum de acusación  \n",
       "6   acusación constitucional; Paro de camiones; pr...    mujeres semidesnudas  \n",
       "7   ultimátum de acusación; acusación constitucion...    mujeres semidesnudas  \n",
       "8   serie de instancias; participación ciudadana; ...      venta de licencias  \n",
       "..                                                ...                     ...  \n",
       "95                                                                             \n",
       "96                                                                             \n",
       "97                                                                             \n",
       "98                                                                             \n",
       "99                                                                             \n",
       "\n",
       "[90 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "dataset[\"most_common\"] = \"\"\n",
    "for i in range(len(dataset)):\n",
    "    split_it = dataset.iloc[i]['terms'].split(\"; \")\n",
    "    counter = Counter(split_it)\n",
    "    dataset['most_common'][i]  = counter.most_common()[0][0]\n",
    "\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "601916de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                            20\n",
       "mujeres semidesnudas         3\n",
       "paro de camioneros           2\n",
       "acusación constitucional     2\n",
       "tomas de terrenos            1\n",
       "                            ..\n",
       "causa de muerte              1\n",
       "franja televisiva            1\n",
       "robos de celulares           1\n",
       "dueños de camiones           1\n",
       "cantidad de horas            1\n",
       "Name: most_common, Length: 67, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['most_common'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943c1b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fdd1db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48a8dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1651b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447d1964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3340491c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80b4631",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, dev_texts, train_labels, dev_labels = train_test_split(df[\"text\"], \n",
    "                                                                    df[\"title\"], \n",
    "                                                                    test_size=0.1, \n",
    "                                                                    shuffle=True, \n",
    "                                                                    random_state=1)\n",
    "\n",
    "print(\"Train:\", len(train_texts))\n",
    "print(\"Dev:\", len(dev_texts))\n",
    "print(\"Test:\", len(test_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383662c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = df['text'][0]\n",
    "display(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084c44d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('spanish')\n",
    "\n",
    "# Convert to list\n",
    "data = text.split(\" \")\n",
    "\n",
    "# Remove new line characters\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "# Remove distracting single quotes\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "\n",
    "\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "        \n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c50ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "print(trigram_mod[bigram_mod[data_words[16]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f3164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "\n",
    "\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e98227",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe6b7f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "id2word[0]\n",
    "texts = data_lemmatized\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9496fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83131d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e106a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6f2bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    print(token.text, token.is_stop, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0415765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('spanish')\n",
    "\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data = text.split(\" \")\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8959a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('spanish')\n",
    "\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data = text.split(\" \")\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b484de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('spanish')\n",
    "\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data = text.split(\" \")\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64226a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3894dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc9edd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67841f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
