{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64cf4d99",
   "metadata": {},
   "source": [
    "# TAL aplicado al análisis del discurso de los medios de prensa 📰🤓🔥\n",
    "\n",
    "\n",
    "Random forest es un algoritmo de aprendizaje supervisado. Se puede utilizar tanto para clasificación como para regresión. También es el algoritmo más flexible y fácil de usar. Random forest está compuesto por árboles. Se dice que cuantos más árboles tiene, más robusto es un bosque. Random forest crea árboles de decisión sobre muestras de datos seleccionadas al azar, obtienen predicciones de cada árbol y seleccionan la mejor solución mediante votación. También proporciona un indicador bastante bueno de la importancia de la función.\n",
    "\n",
    "\n",
    "\n",
    "### índex\n",
    "\n",
    "1. [Importación del dataset](a)\n",
    "2. [Preprocesamiento y representación vectorial](b)\n",
    "3. [Entrenamiento del modelo de clasificación](b)\n",
    "4. [Evaluación del modelo de clasificación](c)\n",
    "\n",
    "    4.4 [Matriz de confusión](d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b15087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54024000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLP\n",
    "import spacy\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "from spacy.lang.es.stop_words import STOP_WORDS\n",
    "from spacy.lang.es import Spanish\n",
    "import string\n",
    "\n",
    "#SKLEARN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression # Regresion Logística\n",
    "\n",
    "# Data manipulation\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e6d362",
   "metadata": {},
   "source": [
    "### 1. Importación del dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ee16af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"topics.csv\",sep=',',error_bad_lines=False)\n",
    "df.drop(['Unnamed: 0'], axis = 1, inplace=True) # Para suprimir la columna ID\n",
    "df.drop(columns=['text','media_outlet', 'url','topic'], inplace=True)\n",
    "\n",
    "df = df.astype({\"label\": str})\n",
    "df.replace(\"0.0\",\"mundo\", inplace=True)\n",
    "df.replace(\"1.0\",\"economia\", inplace=True)\n",
    "df.replace(\"2.0\",\"politica\", inplace=True)\n",
    "df.replace(\"3.0\",\"ciencia\", inplace=True)\n",
    "df.replace(\"6.0\",\"deporte\", inplace=True)\n",
    "df.replace(\"8.0\",\"crimen\", inplace=True)\n",
    "df.replace(\"9.0\",\"salud\", inplace=True)\n",
    "dfc = df[df['label']!=\"5.0\"]\n",
    "dfc = dfc[dfc['label']!=\"7.0\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b3d5a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "undersample = RandomUnderSampler(random_state=0)\n",
    "x_res,y_res = undersample.fit_resample(dfc,dfc['label'])\n",
    "fig, ax = plt.subplots(figsize=(4,4),tight_layout=True)\n",
    "ax = y_res.value_counts().plot.pie(autopct='%.2f')\n",
    "_ = ax.set_title(\"Undersampling\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823be67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_res['content'],y_res, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef678f2",
   "metadata": {},
   "source": [
    "### 2. Preprocesamiento y representación vectorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363cdeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our list of punctuation marks\n",
    "punctuations = [\".\",\",\",\"!\",\"?\", \"#\",\"&\"]\n",
    "\n",
    "# Create our list of stopwords\n",
    "stop_words=[\"\"]\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "parser = Spanish()\n",
    "\n",
    "# Creating our tokenizer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = parser(sentence)\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [word.lower_ for word in mytokens]\n",
    "        \n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30302d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vector = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1))\n",
    "bow_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a6dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c92da1",
   "metadata": {},
   "source": [
    "### 3. Entrenamiento del modelo de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e410cee7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "modelRF = RandomForestClassifier(random_state=0)\n",
    "\n",
    "model3 = Pipeline([('preprocessing', bow_vector),\n",
    "                 ('regression-ML', modelRF)])\n",
    "\n",
    "# model generation\n",
    "model3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f35c29",
   "metadata": {},
   "source": [
    "\n",
    "### 4. Evaluación del modelo de clasificación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578de660",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predicting with a test dataset\n",
    "predicted = model3.predict(X_test)\n",
    "print(predicted)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Logistic Regression Precision:\",metrics.precision_score(y_test, predicted, \n",
    "                                           average='micro'))\n",
    "print(\"Logistic Regression Recall:\",metrics.recall_score(y_test, predicted, \n",
    "                                           average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b000d2",
   "metadata": {},
   "source": [
    "\n",
    "### 4.1. Matriz de confusión\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb9d957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def plot_confusion_matrix(cm, labels, cmap=plt.cm.Blues):\n",
    "    fig, ax = plt.subplots(figsize=(14, 7), tight_layout=True)\n",
    "    ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    for i in range(cm.shape[1]):\n",
    "        for j in range(cm.shape[0]):\n",
    "            ax.text(j, i, \"{:,}\".format(cm[i, j]), \n",
    "                    horizontalalignment=\"center\", verticalalignment=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > np.amax(cm)/2 else \"black\")\n",
    "    ax.set_title(\"Matriz de confusión\")\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    plt.ylabel('Etiqueta real')\n",
    "    plt.xlabel('Predicción')\n",
    "    plt.show()\n",
    "\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=predicted)\n",
    "plot_confusion_matrix(cm, labels=[str(i) for i in range(10)])\n",
    "print(classification_report(y_test, predicted, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94c8ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
