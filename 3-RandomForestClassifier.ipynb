{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64cf4d99",
   "metadata": {},
   "source": [
    "# TAL aplicado al an谩lisis del discurso de los medios de prensa 梆\n",
    "\n",
    "\n",
    "Random forest es un algoritmo de aprendizaje supervisado. Se puede utilizar tanto para clasificaci贸n como para regresi贸n. Tambi茅n es el algoritmo m谩s flexible y f谩cil de usar. Random forest est谩 compuesto por 谩rboles. Se dice que cuantos m谩s 谩rboles tiene, m谩s robusto es un bosque. Random forest crea 谩rboles de decisi贸n sobre muestras de datos seleccionadas al azar, obtienen predicciones de cada 谩rbol y seleccionan la mejor soluci贸n mediante votaci贸n. Tambi茅n proporciona un indicador bastante bueno de la importancia de la funci贸n.\n",
    "\n",
    "\n",
    "\n",
    "### 铆ndex\n",
    "\n",
    "1. [Importaci贸n del dataset](a)\n",
    "2. [Preprocesamiento y representaci贸n vectorial](b)\n",
    "3. [Entrenamiento del modelo de clasificaci贸n](b)\n",
    "4. [Evaluaci贸n del modelo de clasificaci贸n](c)\n",
    "\n",
    "    4.4 [Matriz de confusi贸n](d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b15087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54024000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLP\n",
    "import spacy\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "from spacy.lang.es.stop_words import STOP_WORDS\n",
    "from spacy.lang.es import Spanish\n",
    "import string\n",
    "\n",
    "#SKLEARN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression # Regresion Log铆stica\n",
    "\n",
    "# Data manipulation\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e6d362",
   "metadata": {},
   "source": [
    "### 1. Importaci贸n del dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ee16af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"topics.csv\",sep=',',error_bad_lines=False)\n",
    "df.drop(['Unnamed: 0'], axis = 1, inplace=True) # Para suprimir la columna ID\n",
    "df.drop(columns=['text','media_outlet', 'url','topic'], inplace=True)\n",
    "\n",
    "df = df.astype({\"label\": str})\n",
    "df.replace(\"0.0\",\"mundo\", inplace=True)\n",
    "df.replace(\"1.0\",\"economia\", inplace=True)\n",
    "df.replace(\"2.0\",\"politica\", inplace=True)\n",
    "df.replace(\"3.0\",\"ciencia\", inplace=True)\n",
    "df.replace(\"6.0\",\"deporte\", inplace=True)\n",
    "df.replace(\"8.0\",\"crimen\", inplace=True)\n",
    "df.replace(\"9.0\",\"salud\", inplace=True)\n",
    "dfc = df[df['label']!=\"5.0\"]\n",
    "dfc = dfc[dfc['label']!=\"7.0\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b3d5a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "undersample = RandomUnderSampler(random_state=0)\n",
    "x_res,y_res = undersample.fit_resample(dfc,dfc['label'])\n",
    "fig, ax = plt.subplots(figsize=(4,4),tight_layout=True)\n",
    "ax = y_res.value_counts().plot.pie(autopct='%.2f')\n",
    "_ = ax.set_title(\"Undersampling\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823be67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_res['content'],y_res, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef678f2",
   "metadata": {},
   "source": [
    "### 2. Preprocesamiento y representaci贸n vectorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363cdeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our list of punctuation marks\n",
    "punctuations = [\".\",\",\",\"!\",\"?\", \"#\",\"&\"]\n",
    "\n",
    "# Create our list of stopwords\n",
    "stop_words=[\"\"]\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "parser = Spanish()\n",
    "\n",
    "# Creating our tokenizer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = parser(sentence)\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [word.lower_ for word in mytokens]\n",
    "        \n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30302d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vector = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1))\n",
    "bow_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a6dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c92da1",
   "metadata": {},
   "source": [
    "### 3. Entrenamiento del modelo de clasificaci贸n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e410cee7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "modelRF = RandomForestClassifier(random_state=0)\n",
    "\n",
    "model3 = Pipeline([('preprocessing', bow_vector),\n",
    "                 ('regression-ML', modelRF)])\n",
    "\n",
    "# model generation\n",
    "model3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f35c29",
   "metadata": {},
   "source": [
    "\n",
    "### 4. Evaluaci贸n del modelo de clasificaci贸n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578de660",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predicting with a test dataset\n",
    "predicted = model3.predict(X_test)\n",
    "print(predicted)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Logistic Regression Precision:\",metrics.precision_score(y_test, predicted, \n",
    "                                           average='micro'))\n",
    "print(\"Logistic Regression Recall:\",metrics.recall_score(y_test, predicted, \n",
    "                                           average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b000d2",
   "metadata": {},
   "source": [
    "\n",
    "### 4.1. Matriz de confusi贸n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb9d957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def plot_confusion_matrix(cm, labels, cmap=plt.cm.Blues):\n",
    "    fig, ax = plt.subplots(figsize=(14, 7), tight_layout=True)\n",
    "    ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    for i in range(cm.shape[1]):\n",
    "        for j in range(cm.shape[0]):\n",
    "            ax.text(j, i, \"{:,}\".format(cm[i, j]), \n",
    "                    horizontalalignment=\"center\", verticalalignment=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > np.amax(cm)/2 else \"black\")\n",
    "    ax.set_title(\"Matriz de confusi贸n\")\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    plt.ylabel('Etiqueta real')\n",
    "    plt.xlabel('Predicci贸n')\n",
    "    plt.show()\n",
    "\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=predicted)\n",
    "plot_confusion_matrix(cm, labels=[str(i) for i in range(10)])\n",
    "print(classification_report(y_test, predicted, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94c8ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
